library(RODBC)
channel<-odbcConnect("myodbc", uid = "root", pwd = "ding1122")
data<-sqlFetch(channel,"info")
sqlQuery(channel,'select * from info')
> library(RODBC)
> channel<-odbcConnect("myodbc", uid = "root", pwd = "ding1122")
> data<-sqlFetch(channel,"info")
odbcClose(channel)
library(RODBC)
channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
sqlTables(channel)
odbcClose(channel)
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
> sqlTables(channel)
library(RODBC)
channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
sqlTables(channel)
odbcClose(channel)
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
> sqlTables(channel)
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
odbcClose(channel)
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
odbcClose(channel)
library(RODBC)
odbcClose(channel)
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
library(RODBC)
channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
sqlTables(channel)
closeConnect(channel)
odbcClose(channel)
library(RODBC)
exceldata<-odbcConnectExcel('/Users/CDX/Desktop/test.xlsx',readOnly=FALSE)
？？odbcConnectExcel
？？odbcConnectExcel
help(odbcConnectExcel)
??odbcConnectExcel
exceldata<-odbcConnectExcel('/Users/CDX/Desktop/test.xlsx',readOnly=FALSE)
library(RODBC)
exceldata<-exceldata<-odbcConnectExcel('/Users/CDX/Desktop/test.xlsx',readOnly=FALSE)
library(RODBC)
exceldata<-odbcConnectexcel('/Users/CDX/Desktop/test.xlsx',readOnly=FALSE)
install.packages("RODBC")
？？odbcConnectExcel
library(RODBC)
EXCELDATA<-odbcConnectExcel('/Users/CDX/Desktop/test.xlsx',readOnly=FALSE)
??odbcConnect
clear
clearPushBack
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
library(RODBC)
> channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
channel<-odbcConnect("myodbc",uid="root",pwd="ding1122")
sqlTables(channel)
data(tips,package='reshape2')
install.packages("plyr")
library(plyr)
head(tips)
help(head)
help(file)
output<-file('output.txt')
cat(1:100,sep='\t',file=output)
close(output)
getwd()
output<-file('output.txt')
input<-scan(file=output)
close(output)
head(input)
output<-file('output.txt')
input<-scan(file=output)
close(input)
close(output)
output<-file('output.txt')
input<-scan(file=output)
close(output)
head(input)
input
output<-file('output.txt')
writeLines(as.character(1:12),con=output)
input<-readlines(output)
input<-readLines(output)
input
class(input)
close(output)
head(iris)
data(tips,package='reshape2')
library(plyr)
head(tips)
tips
aggregate(x=tips$tip,
by=list(tip$sex),
FUN=mean)
aggregate(x=tips$tip,
by=list(tips$sex),
FUN=mean)
??data
help(data)
data(tips,package='reshape2')
head(tips)
data(tips,reshape2)
data(list=tips,package=reshape2)
data(list=tips,package='reshape2')
data(tips,package='reshape2')
tips
tips
help(aggregate)
data(tips,package='reshape2')
FUN=mean)
aggregare(x=tips$tip,
by=list(tips$tip),
FUN=mean)
aggregate(x=tips$tip,
by=list(tips$tip),
FUN=mean)
data(tips,package='reshape2')
aggregate(x=tips$tip,
by=list(tips$tip),
FUN=mean)
aggregate(x=tips$tip,
by=list(tips$sex),
FUN=mean)
library(plyr)
ddply(.data=tips,
.variable='sex',
.fun=function(x){mean(x$tip)})
library(plyr)
ddply(tips,
.(sex),
function(x){mean(x$tip)})
ddply(tips,
sex,
function(x){mean(x$tip)})
library(plyr)
ddply(tips,
sex,
function(x){mean(x$tip)})
ddply(tips,
'sex',
function(x){mean(x$tip)})
library(plyr)
ddply(tips,
(sex),
function(x){mean(x$tip)})
ddply(tips,
'sex',
function(x){mean(x$tip)})
ratio_fun<-function(x){
sum(x$tip)/sum(x$total_bill)
}
ddply(tips,.(sex),ratio_fun)
)
head(tips)
m=sum(x$tip)/sum(x$total_bill)
data<-as.matrix(iris[,-5])
data
iris
result4<-adply(.data=data,
.margins=2,
.fun=function(x){each(max,min,median,sd)(x)})
result4
class(iris)
summary(iris)
attribure(iris)
attribute(iris)
attributes(iris)
help(summary)
model<-function(x){lm(Speal.Length~Sepal.Width,data=x)}#建立回归函数
models<-dlply(.data=iris
.variable='Species',
.fun=model)
models<-dlply(.data=iris,
.variable='Species',
.fun=model)
model<-function(x){lm(Spal.Length~Sepal.Width,data=x)}#建立回归函数
models<-dlply(.data=iris,
.variable='Species',
.fun=model)
model<-function(x){lm(Sepal.Length~Sepal.Width,data=x)}#建立回归函数
models<-dlply(.data=iris,
.variable='Species',
.fun=model)
models
result5<-ldply(.data=models,
.fun=coef)
result5
model<-function(x){lm(Sepal.Length~Sepal.Width,
data=x)}#建立回归函数
models<-dlply（iris,
'Species',
.fun=model)
models
model<-function(x){lm(Sepal.Length~Sepal.Width,
data=x)}#建立回归函数
models<-dlply（iris,
.(Species),
library(plyr)
model<-function(x){lm(Sepal.Length~Sepal.Width,
data=x)}#建立回归函数
models<-dlply（iris,
models<-dlply（.data=iris,
.(Species),
.fun=model)
models<-dlply（.data=iris,
model<-function(x){lm(Sepal.Length~Sepal.Width,
data=x)}#建立回归函数
models<-dlply（.data=iris,
..variable='Species',
.fun=model)
models
result5<-ldply(.data=models,
.fun=coef)#三组数据的回归系数
result5
x<-rnorm(30)
x
each(max,min,median,sd)(x)
help(ddply)
library(plyr)
data(tips,package='reshape2')
ddply(tips,
'sex',
function(x){mean(x$tip)})
colwise(median,is.numeric)(iris)
help(rowwise)
load('data/Knicks.rda')
set.seed(1)
x<-seq(1,5,length.out=100)#生成1到5的100个序列
noise<-rnorm(n=100,mean=0,sd=1)#100 个随机噪音
beta0<-1#截距常量
beta1<-2#斜率常量
y<-beta0+beta1*x+noise
plot(y~x)
model<-lm(y~x)#lm=linearmodel
class(model)
abline(model)
model
summary(model)#更加丰富的输出
ybar<-mean(y)
ypred<-model$fitted.values
Rsquared<-sum((ypred-ybar)^2)/sum((y-ybar)^2)
sqrt(sum(model$residuals^2)/98)
Rsqured
Rsquared
yConf<-predict(model,interval='confidence')
yPred<-predict(model,interbal='prediction')
head(yConf)
yPred<-predict(model,interbal='prediction')#对y的个别样本的预测
head(yPred)
yPred
count(yPred)
yConf<-predict(model,interval='confidence')#使用原来建模的数据，
#对y的均值的预测
yPred<-predict(model,interbal='prediction')#对y的个别样本的预测
plot(y~x,col='gray',pch=16)
lines(yConf$lwr~x,col='black',ity=3)
lines(yConf$lwr~x,col='black',ity=3)
lines(yConf$upr~x,col='black',ity=3)
lines(yPred$lwr~x,col='black',ity=2)
lines(yPred$upr~x,col='black',ity=2)
lines(yPred$fix~x,col='black',ity=1)
lines(yConf$lwr~x,col='black',ity=3)
lines(yConf$upr~x,col='black',ity=3)
lines(yPred$lwr~x,col='black',ity=2)
lines(yPred$upr~x,col='black',ity=2)
lines(yPred$fit~x,col='black',ity=1)
yConf<-as.data.frame(yConf)
yPred<-as.data.frame(yPred)
lines(yConf$lwr~x,col='black',ity=3)
lines(yConf$upr~x,col='black',ity=3)
lines(yPred$lwr~x,col='black',ity=2)
lines(yPred$upr~x,col='black',ity=2)
lines(yPred$fit~x,col='black',ity=1)
yConf<-predict(model,interval='confidence')#使用原来建模的数据，
#对y的均值的预测
yPred<-predict(model,interbal='prediction')#对y的个别样本的预测
plot(y~x,col='gray',pch=16)
yConf<-as.data.frame(yConf)
yPred<-as.data.frame(yPred)
lines(yConf$lwr~x,col='black',ity=3)
lines(yConf$upr~x,col='black',ity=3)
lines(yPred$lwr~x,col='black',ity=2)
lines(yPred$upr~x,col='black',ity=2)
lines(yPred$fit~x,col='black',ity=1)
Conf<-predict(model,interval='confidence')#使用原来建模的数据，
#对y的均值的预测
yPred<-predict(model,interbal='prediction')#对y的个别样本的预测
plot(y~x,col='gray',pch=16)
yConf<-as.data.frame(yConf)
yPred<-as.data.frame(yPred)
lines(yConf$lwr~x,col='black',lty=3)
lines(yConf$upr~x,col='black',lty=3)
lines(yPred$lwr~x,col='black',lty=2)
lines(yPred$upr~x,col='black',lty=2)
lines(yPred$fit~x,col='black',lty=1)
#利用模型对新的样本进行预测
yConf<-predict(model,interval='confidence')#使用原来建模的数据，
#对y的均值的预测
yPred<-predict(model,interbal='prediction')#对y的个别样本的预测
plot(y~x,col='gray',pch=16)
yConf<-as.data.frame(yConf)
yPred<-as.data.frame(yPred)
lines(yConf$lwr~x,col='black',lty=3)
lines(yConf$upr~x,col='black',lty=3)
lines(yPred$lwr~x,col='black',lty=2)
lines(yPred$upr~x,col='black',lty=2)
lines(yPred$fit~x,col='black',lty=1)
help(rep)
set.seed(1)
x<-factor(rep(c(0,1),each=30))
y<-c(rnorm(30,0,1),rnorm(30,1,1))
plot(y~x)
model<-lm(y~x)
summary(model)
model.matrix(model)
A=c(1,2,3)
class(A)
mode(A)
length(A)
length(A)+1
class(length(A))
A=1:12
matrix(A,nrow=3,ncol=4)
c=matrix(A,nrow=3,ncol=4)
c
class(c)
help(matrix)
a=c(1:12)
b=seq(2,24,12)
A=matrix(a,nrow=3,ncol=4)
B=matrix(b,nrow=4,ncol=3)
C=matrix(b,nrow=3,ncol=3)
C=matrix(b,nrow=3,ncol=4)
A
B
C
a=c(1:12)
b=seq(2,24,length=12)
A=matrix(a,nrow=3,ncol=4)
B=matrix(b,nrow=4,ncol=3)
C=matrix(b,nrow=3,ncol=4)
A
B
C
A*B
A*C
A%*%C
A%*%B
help(diag)
diag(A)
A
curwd
dir(curwd)
output<-file('output.txt')
cat(1:100,sep='\t',file=output)
close(output)
install.packages("latex2exp")
library(demography)
install.packages("demography")
install.packages("tikzDevice")
library(demography)
library(latex2exp)
fit <- lca(fr.mort)
par(mfrow=c(2,2), mar=c(4,5,2,1), family="serif")
plot(fit$age, fit$ax, type="l", ylab=latex2exp("a_x"), xlab="Age: x")
plot(fit$age, fit$bx, type="l", ylab=latex2exp("b_x"), xlab="Age: x")
plot(0, type="n", axes=FALSE, xlab="", ylab="")
text(1, 0, latex2exp("m_{x,t} = a_x + k_tb_x + e_{x,t}"))
plot(fit$kt, ylab=latex2exp("k_t"), xlab="Year: t")
library(tikzDevice)
fit <- lca(fr.mort)
tikz("tikz-test.tex",width=15/2.54,height=12/2.54)
par(mfrow=c(2,2),mar=c(4,5,2,1),family="serif")
plot(fit[["age"]],fit$ax,type="l",
ylab="$a_x$", xlab="Age: $x$")
plot(fit[["age"]],fit$bx,type="l",
ylab="$b_x$", xlab="Age: $x$")
plot(0,type="n",axes=FALSE,xlab="",ylab="")
text(1,0,"$m_{x,t} = a_x + k_tb_x + e_{x,t}$")
plot(fit$kt,ylab="$k_t$", xlab="Year: $t$")
dev.off()
library("tikzDevice", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
detach("package:tikzDevice", unload=TRUE)
setwd("/Users/CDX/R_workspace/R_project/R_twitter_politics")
getwd()
library("RCurl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("ROAuth")
library(twitteR);library(ROAuth);library(RCurl)
getwd()
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "yR5zJBVo62ttE6c3jqDEZb6Li"
# In consumer secret field, paste the access secret token you got from your Twitter developer application.
consumerSecret <- "BHfSMJVrMaFpQoGAXb2OAmYdQRNPMTacIVvCXB9raauswIjBLb"
twitCred <- OAuthFactory$new(consumerKey=consumerKey, consumerSecret=consumerSecret
, requestURL=requestURL, accessURL=accessURL, authURL=authURL)
twitCred$handshake(cainfo="cacert.pem")
Consumer_key<- "yR5zJBVo62ttE6c3jqDEZb6Li"
Consumer_Secret <-"BHfSMJVrMaFpQoGAXb2OAmYdQRNPMTacIVvCXB9raauswIjBLb"
Access_Token<- "3473101817-icXzDwoqhXP4wu3KULIpOBOwTzA1I9rMeSlVkrw"
Access_Secret <-	"ipgXkA7T0TS5XKPWdAMAEIVjnl5lGN36w9nAaQrmGOlsH"
setup_twitter_oauth(Consumer_key,Consumer_Secret,Access_Token,Access_Secret)
library(twitteR)
library(igraph)
library(stringr)
library(base64enc)
#### twitter api #####
Consumer_key<- "yR5zJBVo62ttE6c3jqDEZb6Li"
Consumer_Secret <-"BHfSMJVrMaFpQoGAXb2OAmYdQRNPMTacIVvCXB9raauswIjBLb"
Access_Token<- "3473101817-icXzDwoqhXP4wu3KULIpOBOwTzA1I9rMeSlVkrw"
Access_Secret <-	"ipgXkA7T0TS5XKPWdAMAEIVjnl5lGN36w9nAaQrmGOlsH"
setup_twitter_oauth(Consumer_key,Consumer_Secret,Access_Token,Access_Secret)
obamacare_tweets = searchTwitter("Obamacare", n=500, lang="en") # tweets in english containing "obamacare"
obamacare_txt = sapply(obamacare_tweets, function(x) x$getText())# get text
save(obamacare_tweets,file="obamacare_tweets.RData")
obamacare_txt = sapply(obamacare_tweets, function(x) x$getText())# get text
grep("(RT|via)((?:\\b\\W*@\\w+)+)", obamacare_tweets, ignore.case=TRUE, value=TRUE) # regular expressions to find retweets
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
obamacare_txt, ignore.case=TRUE)
# show retweets (these are the ones we want to focus on)
obamacare_txt[rt_patterns]
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = obamacare_tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
# unlist
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#### Step 5: Create graph from an edglist ####
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
glay = layout.fruchterman.reingold(rt_graph)
?png
png(filename = "obama_retweet_graph.png")
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("\nTweets with 'obamacare':  Who retweets whom",
cex.main=1, col.main="gray95")
dev.off()
getwd()
png(filename = "obama_retweet_graph.png")
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("\nTweets with 'obamacare':  Who retweets whom",
cex.main=1, col.main="gray95")
dev.off()
png(filename = "obama_retweet_graph2.png")
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color=hsv(h=.35, s=1, v=.7, alpha=0.1),
vertex.frame.color=hsv(h=.35, s=1, v=.7, alpha=0.1),
vertex.size=5,
vertex.label=ver_labs,
vertex.label.family="mono",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.35, s=1, v=.7, alpha=0.4))
# add title
title("\nTweets with 'obamacare':  Who retweets whom",
cex.main=1, col.main="gray95", family="mono")
dev.off()
